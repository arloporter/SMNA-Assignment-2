{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert communities to jsonl so twarc can convert them back to a edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213036/293841221.py:10: DtypeWarning: Columns (63,64,65,66,67,68,69,70,71) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os, json\n",
    "from twarc.expansions import ensure_flattened\n",
    "import subprocess\n",
    "\n",
    "jsonls = []\n",
    "for file in os.listdir('./'):\n",
    "    if file.endswith('.csv'):\n",
    "        df = pd.read_csv(file) \n",
    "        valid_ids = set(df[\"id\"])\n",
    "\n",
    "        with open(\"ukraine_stream_big.jsonl\", \"r\") as infile: \n",
    "            with open(f\"{file}.jsonl\", \"w\") as outfile: \n",
    "                jsonls.append(f\"{file}.jsonl\")\n",
    "                for line in infile: \n",
    "                    for tweet in ensure_flattened(json.loads(line)): \n",
    "                        if int(tweet[\"id\"]) in valid_ids: \n",
    "                            outfile.write(json.dumps(tweet)+\"\\n\")\n",
    "\n",
    "\n",
    "for file in jsonls:\n",
    "    csv_users = file[:-6]+'_users_' + '.csv'\n",
    "    subprocess.call(['twarc2', 'network', file, '--format', 'csv', csv_users, '--min-component-size', '5'])\n",
    "    csv_tweets = file[:-6]+'_tweets_'+'.csv'\n",
    "    subprocess.call(['twarc2', 'network', file, '--format', 'csv', csv_tweets, '--min-component-size', '5', '--nodes', 'tweets'])\n",
    "    csv_tags = file[:-6]+'_tags_'+'.csv'\n",
    "    subprocess.call(['twarc2', 'network', file, '--format', 'csv', csv_tags, '--min-component-size', '5', '--nodes', 'hashtags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community111.csv_tags_.csv\n",
      "   Unnamed: 0                     source      target  weight\n",
      "0           0                     #Putin   #Zelenski     288\n",
      "1           1                     #Putin    #Ucrania      20\n",
      "2           2                     #Putin   #Zelenzsy      20\n",
      "3           3                     #Putin  #Occidente       1\n",
      "4           4  #BedroomSessionsRadioShow      #Rusia       6\n",
      "community111.csv_tweets_.csv\n",
      "   Unnamed: 0        source        target    tweet\n",
      "0           0  1.573014e+18  1.572984e+18    reply\n",
      "1           1  1.573014e+18  1.572612e+18  retweet\n",
      "2           2  1.573015e+18  1.572654e+18  retweet\n",
      "3           3  1.573015e+18  1.573004e+18  retweet\n",
      "4           4  1.573015e+18  1.572925e+18  retweet\n",
      "community111.csv_users_.csv\n",
      "community51.csv_tags_.csv\n",
      "   Unnamed: 0    source              target  weight\n",
      "0           0  #Ukraine             #Tigray    1409\n",
      "1           1  #Ukraine           #Ethiopia      93\n",
      "2           2  #Ukraine          #Palestine       2\n",
      "3           3  #Ukraine         #UkraineWar       2\n",
      "4           4  #Ukraine  #UkraineRussianWar       2\n",
      "community51.csv_tweets_.csv\n",
      "   Unnamed: 0        source        target    tweet\n",
      "0           0  1.573014e+18  1.573002e+18  retweet\n",
      "1           1  1.573014e+18  1.572995e+18  retweet\n",
      "2           2  1.573014e+18  1.573013e+18  retweet\n",
      "3           3  1.573014e+18  1.573002e+18  retweet\n",
      "4           4  1.573014e+18  1.573012e+18  retweet\n",
      "community51.csv_users_.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('./'):\n",
    "    if '_users_' in file:\n",
    "        print(file)\n",
    "        df = pd.read_csv(file, names=['source', 'target', 'weight', 'retweet', 'reply', 'quote', 'mention'])\n",
    "        #df['weight'] = df['weight'].map(lambda y: [int(x) for x in y.split() if x.isdigit()][0])\n",
    "        #df['retweet'] = df['retweet'].map(lambda y: [int(x) for x in y.split() if x.isdigit()][0])\n",
    "        #df['reply'] = df['reply'].map(lambda y: [int(x) for x in y.split() if x.isdigit()][0])\n",
    "        #df['quote'] = df['quote'].map(lambda y: [int(x) for x in y.split() if x.isdigit()][0])\n",
    "        graph = nx.from_pandas_edgelist(df)\n",
    "        df.to_csv(file)\n",
    "        nx.write_gexf(graph, f\"{file}_users_.gexf\")\n",
    "    if '_tweets_' in file:\n",
    "        print(file)\n",
    "        df = pd.read_csv(file)\n",
    "        #df['tweet'] = df['tweet'].map(lambda y: eval(y)['type'])\n",
    "        print(df.head())\n",
    "        graph = nx.from_pandas_edgelist(df)\n",
    "        df.to_csv(file)\n",
    "        nx.write_gexf(graph, f\"{file}_tweets_.gexf\")\n",
    "    if '_tags_' in file:\n",
    "        print(file)\n",
    "        df = pd.read_csv(file)\n",
    "        #df['weight'] = df['weight'].map(lambda y: eval(y)['weight'])\n",
    "        print(df.head())\n",
    "        graph = nx.from_pandas_edgelist(df)\n",
    "        df.to_csv(file)\n",
    "        nx.write_gexf(graph, f\"{file}.gexf\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare communities for retweet BERT\n",
    "## 1. Get edgelist weighted only by retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: twarc2 network [OPTIONS] [INFILE] [OUTFILE]\n",
      "Try 'twarc2 network --help' for help.\n",
      "\n",
      "Error: Invalid value for '[INFILE]': 'community111.csv.jsonl': No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community111_tweets = pd.read_csv('community111.csv')\n",
    "valid_ids = set(community111_tweets[\"id\"])\n",
    "\n",
    "with open(\"ukraine_stream_big.jsonl\", \"r\") as infile: \n",
    "    with open(f\"community111.jsonl\", \"w\") as outfile: \n",
    "            jsonls.append(f\"{file}.jsonl\")\n",
    "            for line in infile: \n",
    "                for tweet in ensure_flattened(json.loads(line)): \n",
    "                    if int(tweet[\"id\"]) in valid_ids: \n",
    "                        outfile.write(json.dumps(tweet)+\"\\n\")\n",
    "\n",
    "csv_network= 'edgelist_111__retweets' + '.csv'\n",
    "subprocess.call(['twarc2', 'network', 'community111.csv.jsonl', '--format', 'csv', csv_users, '--min-component-size', '5', '--edges', 'retweet'])\n",
    "\n",
    "csv_network= 'edgelist_51__retweets' + '.csv'\n",
    "subprocess.call(['twarc2', 'network', 'community51.csv.jsonl', '--format', 'csv', csv_users, '--min-component-size', '5', '--edges', 'retweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get csv of author names and author decriptions for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in community272_tweets:\n",
    "    new_df = \n",
    "    author = row['author.name']\n",
    "    description = row['author.description']\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0922385216c2384f31190554b3bde2d497dc7ba4e166eada6ff2c309b47fae1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
